{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Physics informed Neural Net\n",
    "\n",
    "Here we implement a  example from the paper by [Raissi et al 2019](https://www.sciencedirect.com/science/article/pii/S0021999118307125?casa_token=qU5V_mqCUkYAAAAA:vCncJgWLW6Ac8OJbVOGSN9Gii4Bh6-i2woHLkOpDF6UKbl2JeUowNwtfNs_62kZdMaAx5O_FHg)\n",
    "\n",
    "## Solving the Burgers equation\n",
    "\n",
    "See Appendix 1 of paper\n",
    "- $du/dt + u du/dx - (0.01*\\pi) d^2u/dx^2 =0$,  $x \\in [-1,1], t \\in [0,1]$\n",
    "- $u(0,x)=-sin(\\pi x)$\n",
    "- $u(t,-1)=0$ if $u>0$\n",
    "- $u(t,1)=0$ if $u<0$\n",
    "\n",
    "Note that the boundary conditions are not properly defined for this equation. The sign of u at the boundary is ignored and the diffusion term has no boundary condition. \n",
    "This probably works because the flow is away from the boundary at both sides, due to the initial condition.\n",
    "\n",
    "\n",
    "__NOTE__\n",
    "\n",
    "There are issues in the combination of Flux and Zygote for this application. See for example [here](https://discourse.julialang.org/t/using-flux-for-a-neural-net-solution-to-differential-equations/41996/4)  and [here](https://discourse.julialang.org/t/gradient-error-in-flux-model-inputs/53259/2) and [here](https://github.com/FluxML/Flux.jl/issues/1464)\n",
    "\n",
    "The root cause seems to be the immutability of arrays, see [here](https://fluxml.ai/Zygote.jl/stable/limitations/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "## Install Flux if needed\n",
    "#import Pkg\n",
    "#Pkg.add(\"Flux\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# With Julia 1.7+, this will prompt if neccessary to install everything, including CUDA:\n",
    "using Flux\n",
    "using LinearAlgebra\n",
    "using Statistics\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##  Dense NN for $u(t,x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Define our model of u(t,x) as a dense network\n",
    "n1=50\n",
    "n2=50\n",
    "model = Chain(Dense(2 => n1, tanh), BatchNorm(n1), Dense(n1 => n2,tanh),Dense(n2 => 1,tanh)) #1 since u maps to R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "model([0.5 0.5]') #random after initialization, but before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "u(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# settings\n",
    "n_train = 1000   #number of training points for interior\n",
    "n_test  = 1000   #number of testing points for interior\n",
    "n_init_train = 30   #number of training points for initial condition\n",
    "n_init_test  = 30   #number of testing points for initial condition\n",
    "n_bound_train = 30  #number of training points at either boundary\n",
    "n_bound_test = 30  #number of testing points at either boundary\n",
    "xmin=-1.0\n",
    "xmax=1.0\n",
    "tmin=0.0\n",
    "tmax=1.0\n",
    "\n",
    "# Interior\n",
    "function random_points(xmin,xmax,tmin,tmax,n)\n",
    "    temp = rand(Float32,2,n)\n",
    "    temp[1,:].=xmin.+(xmax-xmin).*temp[1,:]\n",
    "    temp[2,:].=tmin.+(tmax-tmin).*temp[2,:]\n",
    "    return temp\n",
    "end\n",
    "#  select training and testing points for interior\n",
    "xt_train = random_points(xmin,xmax,tmin,tmax,n_train)\n",
    "yt_prior = model(xt_train)\n",
    "xt_test  = random_points(xmin,xmax,tmin,tmax,n_test)\n",
    "# initial condition\n",
    "xt_init_train = random_points(xmin,xmax,tmin,tmin,n_init_train)\n",
    "yt_init_prior = model(xt_init_train)\n",
    "xt_init_test  = random_points(xmin,xmax,tmin,tmin,n_init_test)\n",
    "# left boundary\n",
    "xt_left_train = random_points(xmin,xmin,tmin,tmax,n_bound_train)\n",
    "yt_left_prior = model(xt_left_train)\n",
    "xt_left_test  = random_points(xmin,xmin,tmin,tmax,n_bound_test)\n",
    "# right boundary\n",
    "xt_right_train = random_points(xmax,xmax,tmin,tmax,n_bound_train)\n",
    "yt_right_prior = model(xt_right_train)\n",
    "xt_right_test  = random_points(xmax,xmax,tmin,tmax,n_bound_test)\n",
    "\n",
    "nothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "\n",
    "p_prior = scatter(xt_train[1,:], xt_train[2,:], zcolor=yt_prior[1,:], title=\"UNtrained network\", legend=true,clims=(-1,1),label=\"u(x,t)\",xlabel=\"x\",ylabel=\"t\")\n",
    "scatter!(p_prior, xt_left_train[1,:], xt_left_train[2,:], zcolor=yt_left_prior[1,:],label=\"u(-1,t)\")\n",
    "scatter!(p_prior, xt_right_train[1,:], xt_right_train[2,:], zcolor=yt_right_prior[1,:],label=\"u(1,t)\")\n",
    "scatter!(p_prior, xt_init_train[1,:], xt_init_train[2,:], zcolor=yt_init_prior[1,:],label=\"u(x,0)\")\n",
    "plot(p_prior, layout=(1,1), size=(700,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "n1=50\n",
    "n2=50\n",
    "model = Chain(Dense(2 => n1, tanh), Dense(n1 => 1,tanh)) #1 since u maps to R\n",
    "\n",
    "u(x,t)    = model(reshape([x,t],2,1))[1]\n",
    "du(x,t)   = gradient(u,x,t)\n",
    "dudx(x,t) = du(x,t)[1]\n",
    "dudt(x,t) = du(x,t)[2]\n",
    "\n",
    "res(x,t)  = dudt(x,t) + u(x,t) * dudx(x,t) # Equation for the interior\n",
    "\n",
    "res_init(x,t) = u(x,t)+sin(π*x)\n",
    "\n",
    "res_left(x,t)  = u(x,t)\n",
    "res_right(x,t) = u(x,t)\n",
    "\n",
    "function interior_loss(xt)\n",
    "    loss=0.0\n",
    "    for ipoint=1:size(xt,2)\n",
    "        x         = xt[1,ipoint]\n",
    "        t         = xt[2,ipoint]\n",
    "        loss  = loss + res(x,t)^2\n",
    "    end\n",
    "    return loss\n",
    "end\n",
    "\n",
    "function initial_loss(xt)\n",
    "    loss=0.0\n",
    "    for ipoint=1:size(xt,2)\n",
    "        x         = xt[1,ipoint]\n",
    "        t         = xt[2,ipoint]\n",
    "        loss  = loss + res_init(x,t)^2\n",
    "    end\n",
    "    return loss\n",
    "end\n",
    "\n",
    "interior_loss(xt_train)+initial_loss(xt_init_train)\n",
    "\n",
    "#opt = Flux.Adam(0.01)      # will store optimiser momentum, etc.\n",
    "#pars = Flux.params(model)  # contains references to arrays in model\n",
    "#gs = gradient(pars) do\n",
    "#    return initial_loss(xt_init_train)\n",
    "#end\n",
    "#Flux.Optimise.update!(opt,pars,gs)\n",
    "\n",
    "xt=xt_train[:,1:5]\n",
    "pars = Flux.params(model)\n",
    "grad = gradient(()->interior_loss(xt),pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "interior_loss(xt_train)+initial_loss(xt_init_train)\n",
    "\n",
    "opt = Flux.Adam(0.01)      # will store optimiser momentum, etc.\n",
    "pars = Flux.params(model)  # contains references to arrays in model\n",
    "gs = gradient(pars) do\n",
    "    return interior_loss(xt_train)+initial_loss(xt_init_train)\n",
    "end\n",
    "Flux.Optimise.update!(opt,pars,gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "pars = Flux.params(model)  # contains references to arrays in model\n",
    "opt = Flux.Adam(0.01)      # will store optimiser momentum, etc.\n",
    "#data = Flux.DataLoader((rand(2,10), rand(1,10)), batchsize=10, shuffle=false) #fake data\n",
    "\n",
    "loss(x,y)=interior_loss(xt_train)+initial_loss(xt_init_train) #ignore data TODO: this is a mess\n",
    "\n",
    "#Flux.train!(loss, pars, data, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "interior_loss(xt_train)+initial_loss(xt_init_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "model([0.25 0.75 0.25 0.75 ; 0.25 0.25 0.75 0.75]) #apply the trained model, with one point in each colunm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "model # show summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8",
   "env": {
    "JULIA_DEPOT_PATH": "/home/user/.julia/:/ext/julia/depot/",
    "JULIA_PROJECT": "/home/user/.julia/environment/v1.8"
   },
   "language": "julia",
   "metadata": {
    "cocalc": {
     "description": "The Julia Programming Language",
     "priority": 10,
     "url": "https://julialang.org/"
    }
   },
   "name": "julia-1.8",
   "resource_dir": "/ext/jupyter/kernels/julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}